Commit b1f214c12fb29ef4c55d7f75fea0a07f3b287174 by Abdullah Bakir <abdullah.bakir.204@gmail.com>
Date:   Wed Dec 27 09:36:55 2023 +0100

    test 2

diff --git a/bot/__pycache__/admin.cpython-311.pyc b/bot/__pycache__/admin.cpython-311.pyc
new file mode 100644
index 0000000..a7e2abf
Binary files /dev/null and b/bot/__pycache__/admin.cpython-311.pyc differ
diff --git a/bot/__pycache__/models.cpython-311.pyc b/bot/__pycache__/models.cpython-311.pyc
new file mode 100644
index 0000000..5db8c72
Binary files /dev/null and b/bot/__pycache__/models.cpython-311.pyc differ
diff --git a/file_names.txt b/file_names.txt
new file mode 100644
index 0000000..46d094a
--- /dev/null
+++ b/file_names.txt
@@ -0,0 +1,270 @@
+.git
+bot
+db.sqlite3
+manage.py
+posts
+project
+todo.md
+Files in C:\Users\B\Project\bot\src:
+
+Folder: C:\Users\B\Project\bot\src
+db.sqlite3
+file_names.txt
+manage.py
+todo.md
+
+Folder: C:\Users\B\Project\bot\src\.git
+COMMIT_EDITMSG
+config
+description
+HEAD
+index
+
+Folder: C:\Users\B\Project\bot\src\.git\hooks
+applypatch-msg.sample
+commit-msg.sample
+fsmonitor-watchman.sample
+post-update.sample
+pre-applypatch.sample
+pre-commit.sample
+pre-merge-commit.sample
+pre-push.sample
+pre-rebase.sample
+pre-receive.sample
+prepare-commit-msg.sample
+push-to-checkout.sample
+update.sample
+
+Folder: C:\Users\B\Project\bot\src\.git\info
+exclude
+
+Folder: C:\Users\B\Project\bot\src\.git\logs
+HEAD
+
+Folder: C:\Users\B\Project\bot\src\.git\logs\refs
+
+Folder: C:\Users\B\Project\bot\src\.git\logs\refs\heads
+first
+
+Folder: C:\Users\B\Project\bot\src\.git\logs\refs\remotes
+
+Folder: C:\Users\B\Project\bot\src\.git\logs\refs\remotes\origin
+first
+main
+
+Folder: C:\Users\B\Project\bot\src\.git\objects
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\08
+e805714e689aeb06452b9812ba9ccab69dcab9
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\09
+9ff0d4f125ed42dc174c6167cd3a5b2dc87b23
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\0c
+789ed6ebfbed1d95cb71351000df52c92025da
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\0d
+bd3ce19a3cc62aec7d9d6c3504e869dfe569a5
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\17
+e93b065dafccca4875e79d821e43911e345b42
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\1c
+d7ff2e777438a9e2f10782d5aa55ef1771e290
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\20
+571578b0a53f6b0a75f0922e52a8970934c741
+e99d736f941d2ac3ea53a7c0377296b4067bf9
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\26
+84fd709af097b7f575dd84bbaeff87f3fed4b8
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\27
+c039acc2ec0c308b101d6a7a4a701d2b57b931
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\2c
+49f3ac22774ee37666fd8bad6f7ed1c8069756
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\31
+81f0043c0dda69e7ec39d5e394c10ff4a4bbc5
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\32
+8015c0baa7a33cb24eadb3a8410ca228ab14d0
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\36
+a1a9b9ecdf6aa76349d16467928d1b480bb71a
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\37
+d258f7d51690d27e59c40a954cde4e9a5b897b
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\3d
+b37b434e141ab63cb804750d708e13ff1327d2
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\41
+718745b2554377b0a912f3d242c34c07c6b474
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\45
+89aa7b4a028e7eb7cf83611e06b368da17f19d
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\49
+99e0176c9601fe53c73cc54055f28b207d10a2
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\50
+029ccec8cd6da616b16db8ee4b292adac7d9f8
+87b98b7db1600a973ea17c0f9ec7df6490aa13
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\52
+4187801e7aab4c8f3ca9d380f3e29046f750cb
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\56
+37ceb344c9aa09e547e1c68c52a695d99404a5
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\59
+7c60cfa9cb621446c433010785a083c171ca2c
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\5c
+6f039ffa77c214a603af868f93b079d4dc5dc1
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\68
+4174afd679de6ae98cd19289b504226b720f0c
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\6a
+50fab1e8890307156f48e0d16adb2c06da5aff
+f67fb9100a1f1d5b42614b15648b8469f01c3c
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\6e
+15681431fcded0510f66fe4a0ed675fed59586
+d56d7b8a798209d4abc2ea4ae26712454a93f5
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\71
+a836239075aa6e6e4ecb700e9c42c95c022d91
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\79
+bc8d9a6efc22775f118d9723582441c88b8a93
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\7c
+e503c2dd97ba78597f6ff6e4393132753573f6
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\8c
+38f3f3dad51e4585f3984282c2a4bec5349c1e
+46bcb68ece22523b48ae5aa7fcf4349c735777
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\91
+8b15fa7f52b55ff3a6c62d5e39480a0e4bf580
+ea44a218fbd2f408430959283f0419c921093e
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\92
+80d31f7c184f68d2a8ef91eb796a667ff10d53
+99f76ec8d94b86d4d046cc38d003c43b15ae36
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\9d
+1dcfdaf1a6857c5f83dc27019c7600e1ffaff8
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\b1
+8ed0dcb3371478f1ca309cde1ef0749cd42a53
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\b3
+f335792c1902d8714f526a8b0fed61f175a886
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\b8
+9c667432a8be38f970c42b455a7c197391a618
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\bf
+b308c531bc8886ab7f7a6a0aeb7ba829aca600
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\c7
+a959e71788a69f03ab0187334c4aaee656168a
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\cd
+336a8955d67015de616ce12813a3f0b0369f25
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\ce
+ff8608808c11e537cc4ed4eef9d1150f7f959f
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\df
+b8da18482094e338de8c6d6bc8bd18ba377257
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\e6
+9de29bb2d1d6434b8b29ae775ad8c2e48c5391
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\f1
+4337a3f806432efd89c8dad9f3da3ac0e863f1
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\fc
+d714528bff3c175d20b05a41d2534e98f60d02
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\ff
+802aae0dfbc29f39529099ce516376d2da2bb2
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\info
+
+Folder: C:\Users\B\Project\bot\src\.git\objects\pack
+
+Folder: C:\Users\B\Project\bot\src\.git\refs
+
+Folder: C:\Users\B\Project\bot\src\.git\refs\heads
+first
+
+Folder: C:\Users\B\Project\bot\src\.git\refs\remotes
+
+Folder: C:\Users\B\Project\bot\src\.git\refs\remotes\origin
+first
+main
+
+Folder: C:\Users\B\Project\bot\src\.git\refs\tags
+
+Folder: C:\Users\B\Project\bot\src\bot
+admin.py
+apps.py
+models.py
+tests.py
+views.py
+__init__.py
+
+Folder: C:\Users\B\Project\bot\src\bot\migrations
+__init__.py
+
+Folder: C:\Users\B\Project\bot\src\bot\__pycache__
+apps.cpython-311.pyc
+__init__.cpython-311.pyc
+
+Folder: C:\Users\B\Project\bot\src\posts
+admin.py
+apps.py
+bert_keyword_extraction.py
+create_file_names.py
+models.py
+ner.py
+tests.py
+textrank.py
+tfidf.py
+urls.py
+utils.py
+views.py
+__init__.py
+
+Folder: C:\Users\B\Project\bot\src\posts\migrations
+__init__.py
+
+Folder: C:\Users\B\Project\bot\src\posts\templates
+
+Folder: C:\Users\B\Project\bot\src\posts\templates\posts
+create_post.html
+post.html
+
+Folder: C:\Users\B\Project\bot\src\posts\__pycache__
+apps.cpython-311.pyc
+__init__.cpython-311.pyc
+
+Folder: C:\Users\B\Project\bot\src\project
+asgi.py
+settings.py
+urls.py
+wsgi.py
+__init__.py
+
+Folder: C:\Users\B\Project\bot\src\project\__pycache__
+settings.cpython-311.pyc
+urls.cpython-311.pyc
+wsgi.cpython-311.pyc
+__init__.cpython-311.pyc
diff --git a/manage.py b/manage.py
index b3f3357..77f33c9 100644
--- a/manage.py
+++ b/manage.py
@@ -21,7 +21,7 @@ def main():
 
 
 # Load the pre-trained BERT model
-    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)
+    # model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)
 
 # Rest of your code
 # ...
diff --git a/posts/__pycache__/admin.cpython-311.pyc b/posts/__pycache__/admin.cpython-311.pyc
new file mode 100644
index 0000000..08e171f
Binary files /dev/null and b/posts/__pycache__/admin.cpython-311.pyc differ
diff --git a/posts/__pycache__/forms.cpython-311.pyc b/posts/__pycache__/forms.cpython-311.pyc
new file mode 100644
index 0000000..2dace91
Binary files /dev/null and b/posts/__pycache__/forms.cpython-311.pyc differ
diff --git a/posts/__pycache__/models.cpython-311.pyc b/posts/__pycache__/models.cpython-311.pyc
new file mode 100644
index 0000000..143c0a5
Binary files /dev/null and b/posts/__pycache__/models.cpython-311.pyc differ
diff --git a/posts/__pycache__/ner.cpython-311.pyc b/posts/__pycache__/ner.cpython-311.pyc
new file mode 100644
index 0000000..25ee93d
Binary files /dev/null and b/posts/__pycache__/ner.cpython-311.pyc differ
diff --git a/posts/__pycache__/textrank.cpython-311.pyc b/posts/__pycache__/textrank.cpython-311.pyc
new file mode 100644
index 0000000..a5748b9
Binary files /dev/null and b/posts/__pycache__/textrank.cpython-311.pyc differ
diff --git a/posts/__pycache__/tfidf.cpython-311.pyc b/posts/__pycache__/tfidf.cpython-311.pyc
new file mode 100644
index 0000000..8738648
Binary files /dev/null and b/posts/__pycache__/tfidf.cpython-311.pyc differ
diff --git a/posts/__pycache__/urls.cpython-311.pyc b/posts/__pycache__/urls.cpython-311.pyc
new file mode 100644
index 0000000..8cd14a3
Binary files /dev/null and b/posts/__pycache__/urls.cpython-311.pyc differ
diff --git a/posts/__pycache__/views.cpython-311.pyc b/posts/__pycache__/views.cpython-311.pyc
new file mode 100644
index 0000000..c194e52
Binary files /dev/null and b/posts/__pycache__/views.cpython-311.pyc differ
diff --git a/posts/admin.py b/posts/admin.py
index c7a959e..ba08b53 100644
--- a/posts/admin.py
+++ b/posts/admin.py
@@ -1,3 +1,9 @@
 from django.contrib import admin
+from .models import Post
 
 
+
+# Register the admin class
+
+admin.site.register(Post)
+
diff --git a/posts/bert_keyword_extraction.py b/posts/bert_keyword_extraction.py
index 099ff0d..8dff0fe 100644
--- a/posts/bert_keyword_extraction.py
+++ b/posts/bert_keyword_extraction.py
@@ -37,3 +37,4 @@ for token, label in zip(tokens, predicted_token_labels[1:-1]):
 
 # Print the extracted keywords
 print(keywords)
+
diff --git a/posts/create_file_names.py b/posts/create_file_names.py
new file mode 100644
index 0000000..9517b54
--- /dev/null
+++ b/posts/create_file_names.py
@@ -0,0 +1,24 @@
+import os
+
+# Get the current directory
+current_dir = os.getcwd()
+
+# Specify the output file path
+output_file_path = "file_names.txt"
+
+# Open the output file in append mode
+with open(output_file_path, 'a') as output_file:
+    
+    # Write the current directory name to the file
+    output_file.write(f"Files in {current_dir}:\n")
+    
+    # Get a list of all files in the current directory and its subdirectories
+    for foldername, subfolders, filenames in os.walk(current_dir):
+        # Write the folder name to the file
+        output_file.write(f"\nFolder: {foldername}\n")
+        
+        # Write the names of all files in the folder to the file
+        for filename in filenames:
+            output_file.write(filename + '\n')
+
+print(f"File names have been appended to '{output_file_path}'.")
diff --git a/posts/forms.py b/posts/forms.py
new file mode 100644
index 0000000..0a7c6b4
--- /dev/null
+++ b/posts/forms.py
@@ -0,0 +1,8 @@
+# forms.py
+from django import forms
+from .models import Post
+
+class PostCreationForm(forms.ModelForm):
+    class Meta:
+        model = Post
+        fields = ['subject', 'important_things', 'libraries', 'frameworks', 'tools', 'best_practices', 'benefits', 'examples', 'implementation_instructions', 'installation_guidelines', 'settings', 'things_to_avoid', 'top_keywords']
diff --git a/posts/models.py b/posts/models.py
index 9280d31..cbcbfc7 100644
--- a/posts/models.py
+++ b/posts/models.py
@@ -1,24 +1,27 @@
 from django.db import models
-
+from django.contrib.auth.models import User
 
 class Post(models.Model):
+    user = models.ForeignKey(User, on_delete=models.CASCADE, null=True, blank=True)
     subject = models.CharField(max_length=200)
-    important_things = models.TextField(null=True,blank=True)
-    libraries = models.TextField(null=True,blank=True)
-    frameworks = models.TextField(null=True,blank=True)
-    tools = models.TextField(null=True,blank=True)
-    best_practices = models.TextField(null=True,blank=True)
-    benefits = models.TextField(null=True,blank=True)
-    examples = models.TextField(null=True,blank=True)
-    implementation_instructions = models.TextField(null=True,blank=True)
-    installation_guidelines = models.TextField(null=True,blank=True)
-    settings = models.TextField(null=True,blank=True)
-    things_to_avoid = models.TextField(null=True,blank=True)
-    follow = models.TextField(null=True,blank=True)
+    important_things = models.TextField(null=True, blank=True)
+    libraries = models.TextField(null=True, blank=True)
+    frameworks = models.TextField(null=True, blank=True)
+    tools = models.TextField(null=True, blank=True)
+    best_practices = models.TextField(null=True, blank=True)
+    benefits = models.TextField(null=True, blank=True)
+    examples = models.TextField(null=True, blank=True)
+    implementation_instructions = models.TextField(null=True, blank=True)
+    installation_guidelines = models.TextField(null=True, blank=True)
+    settings = models.TextField(null=True, blank=True)
+    things_to_avoid = models.TextField(null=True, blank=True)
+    follow = models.TextField(null=True, blank=True)
     created_at = models.DateTimeField(auto_now_add=True)
     updated_at = models.DateTimeField(auto_now=True)
-    hashtags = models.TextField(null=True,blank=True)
-    top_keywords = models.TextField(null=True,blank=True)
+    hashtags = models.TextField(null=True, blank=True)
+    top_keywords = models.TextField(null=True, blank=True)
+    textrank_keywords = models.TextField(null=True, blank=True)
+
 
-    def _str_(self):
-        return self.subject
\ No newline at end of file
+    def __str__(self):
+        return self.subject
diff --git a/posts/ner.py b/posts/ner.py
index bfb308c..6c21501 100644
--- a/posts/ner.py
+++ b/posts/ner.py
@@ -1,20 +1,18 @@
 import spacy
-from spacy.lang.en import English
+
+# Load the spaCy language model
+nlp = spacy.load('en_core_web_sm')
 
 def extract_named_entities_with_spacy(text):
-    nlp = spacy.load('en_core_web_sm')
-    tokenizer = English().Defaults.create_tokenizer(nlp)
-    
-    # Tokenize the text
-    tokens = tokenizer(text)
-    
-    # Create a spaCy document
-    doc = spacy.tokens.Doc(nlp.vocab, words=[token.text for token in tokens])
-    
-    # Apply named entity recognition
-    nlp.get_pipe("ner")(doc)
+    # Create a spaCy document that also runs the NER pipeline component
+    doc = nlp(text)
     
     # Extract named entities
-    named_entities = [ent.text for ent in doc.ents]
+    named_entities = [(ent.text, ent.label_) for ent in doc.ents]
     
-    return named_entities
\ No newline at end of file
+    return named_entities
+
+# Example usage
+if __name__ == "__main__":
+    sample_text = "Apple is looking at buying U.K. startup for $1 billion"
+    print(extract_named_entities_with_spacy(sample_text))
\ No newline at end of file
diff --git a/posts/templates/posts/create_post.html b/posts/templates/posts/create_post.html
index 2057157..bd777b2 100644
--- a/posts/templates/posts/create_post.html
+++ b/posts/templates/posts/create_post.html
@@ -1,52 +1,107 @@
 <!DOCTYPE html>
-<html>
+<html lang="en">
 <head>
+    <meta charset="UTF-8">
+    <meta name="viewport" content="width=device-width, initial-scale=1.0">
     <title>Create Post</title>
+    <!-- Add any additional CSS styling or links to external stylesheets here -->
+    <style>
+        body {
+            font-family: Arial, sans-serif;
+            margin: 20px;
+            background-color: #f4f4f4;
+        }
+
+        h1 {
+            color: #333;
+            text-align: center;
+        }
+
+        form {
+            max-width: 600px;
+            margin: 20px auto;
+            background-color: #fff;
+            padding: 20px;
+            border-radius: 8px;
+            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
+        }
+
+        label {
+            display: block;
+            margin-bottom: 8px;
+            color: #555;
+        }
+
+        input, textarea {
+            width: 100%;
+            padding: 10px;
+            margin-bottom: 15px;
+            box-sizing: border-box;
+            border: 1px solid #ccc;
+            border-radius: 4px;
+        }
+
+        input[type="submit"] {
+            background-color: #4CAF50;
+            color: white;
+            cursor: pointer;
+            border: none;
+            padding: 12px 20px;
+            border-radius: 4px;
+        }
+
+        input[type="submit"]:hover {
+            background-color: #45a049;
+        }
+
+        /* Add any additional styling as needed */
+    </style>
 </head>
 <body>
     <h1>Create a New Post</h1>
     <form method="POST" action="{% url 'create_post' %}">
         {% csrf_token %}
+        
         <label for="subject">Subject:</label>
-        <input type="text" name="subject" id="subject" required><br><br>
+        <input type="text" name="subject" id="subject" required>
         
         <label for="important_things">Important Things:</label>
-        <textarea name="important_things" id="important_things"></textarea><br><br>
+        <textarea name="important_things" id="important_things" rows="4"></textarea>
         
         <label for="libraries">Libraries:</label>
-        <textarea name="libraries" id="libraries"></textarea><br><br>
+        <textarea name="libraries" id="libraries" rows="4"></textarea>
         
         <label for="frameworks">Frameworks:</label>
-        <textarea name="frameworks" id="frameworks"></textarea><br><br>
+        <textarea name="frameworks" id="frameworks" rows="4"></textarea>
         
         <label for="tools">Tools:</label>
-        <textarea name="tools" id="tools"></textarea><br><br>
+        <textarea name="tools" id="tools" rows="4"></textarea>
         
         <label for="best_practices">Best Practices:</label>
-        <textarea name="best_practices" id="best_practices"></textarea><br><br>
+        <textarea name="best_practices" id="best_practices" rows="4"></textarea>
         
         <label for="benefits">Benefits:</label>
-        <textarea name="benefits" id="benefits"></textarea><br><br>
+        <textarea name="benefits" id="benefits" rows="4"></textarea>
         
         <label for="examples">Examples:</label>
-        <textarea name="examples" id="examples"></textarea><br><br>
+        <textarea name="examples" id="examples" rows="4"></textarea>
         
         <label for="implementation_instructions">Implementation Instructions:</label>
-        <textarea name="implementation_instructions" id="implementation_instructions"></textarea><br><br>
+        <textarea name="implementation_instructions" id="implementation_instructions" rows="4"></textarea>
         
         <label for="installation_guidelines">Installation Guidelines:</label>
-        <textarea name="installation_guidelines" id="installation_guidelines"></textarea><br><br>
+        <textarea name="installation_guidelines" id="installation_guidelines" rows="4"></textarea>
         
         <label for="settings">Settings:</label>
-        <textarea name="settings" id="settings"></textarea><br><br>
+        <textarea name="settings" id="settings" rows="4"></textarea>
         
         <label for="things_to_avoid">Things to Avoid:</label>
-        <textarea name="things_to_avoid" id="things_to_avoid"></textarea><br><br>
+        <textarea name="things_to_avoid" id="things_to_avoid" rows="4"></textarea>
         
         <label for="top_keywords">Top Keywords:</label>
-        <textarea name="top_keywords" id="top_keywords"></textarea><br><br>
+        <textarea name="top_keywords" id="top_keywords" rows="4"></textarea>
         
         <input type="submit" value="Create Post">
     </form>
 </body>
-</html>
\ No newline at end of file
+</html>
diff --git a/posts/templates/posts/post.html b/posts/templates/posts/generated_post.html
similarity index 53%
rename from posts/templates/posts/post.html
rename to posts/templates/posts/generated_post.html
index 36a1a9b..9821dc3 100644
--- a/posts/templates/posts/post.html
+++ b/posts/templates/posts/generated_post.html
@@ -1,7 +1,44 @@
 <!DOCTYPE html>
-<html>
+<html lang="en">
 <head>
+    <meta charset="UTF-8">
+    <meta name="viewport" content="width=device-width, initial-scale=1.0">
     <title>Generated Post</title>
+    <!-- Add any additional CSS styling or links to external stylesheets here -->
+    <style>
+        body {
+            font-family: Arial, sans-serif;
+            margin: 20px;
+            background-color: #f4f4f4;
+        }
+
+        h1, h2, h3 {
+            color: #333;
+        }
+
+        h1 {
+            border-bottom: 2px solid #333;
+            padding-bottom: 10px;
+            text-align: center;
+        }
+
+        h2 {
+            margin-top: 20px;
+            color: #4CAF50;
+        }
+
+        h3 {
+            margin-top: 15px;
+            color: #555;
+        }
+
+        p {
+            color: #777;
+            line-height: 1.6;
+        }
+
+        /* Add any additional styling as needed */
+    </style>
 </head>
 <body>
     <h1>Generated Post</h1>
@@ -43,4 +80,4 @@
     <h3>Top Keywords:</h3>
     <p>{{ post.top_keywords }}</p>
 </body>
-</html>
\ No newline at end of file
+</html>
diff --git a/posts/textrank.py b/posts/textrank.py
index 8c46bcb..7e673a8 100644
--- a/posts/textrank.py
+++ b/posts/textrank.py
@@ -1,21 +1,20 @@
 import spacy
 from spacy.lang.en.stop_words import STOP_WORDS
-from spacy.lang.en import English
-from collections import defaultdict
 import string
+from collections import defaultdict
 
-# Load the spaCy language model
+# Load the spaCy English language model
 nlp = spacy.load('en_core_web_sm')
 
-# Create a tokenizer
-tokenizer = English().Defaults.create_tokenizer(nlp)
-
 def preprocess_input(text):
-    # Tokenize the text
-    tokens = tokenizer(text)
+    # Tokenize the text using spaCy's built-in tokenizer
+    tokens = nlp.tokenizer(text)
 
-    # Remove stopwords and punctuation
-    tokens = [token.text.lower() for token in tokens if token.text.lower() not in STOP_WORDS and token.text not in string.punctuation]
+    # Remove stopwords and punctuation from tokens
+    tokens = [
+        token.text.lower() for token in tokens 
+        if not token.is_stop and not token.is_punct
+    ]
 
     # Join the tokens back into a string
     preprocessed_text = ' '.join(tokens)
@@ -25,25 +24,36 @@ def extract_keywords_with_textrank(text, num_keywords=5):
     # Preprocess the text
     preprocessed_text = preprocess_input(text)
 
-    # Create a spaCy document
+    # Create a spaCy document from the preprocessed text
     doc = nlp(preprocessed_text)
 
     # Build the word frequency dictionary
     word_frequencies = defaultdict(int)
     for token in doc:
-        word_frequencies[token.text] += 1
+        if not token.is_stop and not token.is_punct:
+            word_frequencies[token.text] += 1
 
     # Normalize the word frequencies
     max_frequency = max(word_frequencies.values())
-    word_frequencies = {word: freq / max_frequency for word, freq in word_frequencies.items()}
+    for word in word_frequencies:
+        word_frequencies[word] /= max_frequency
 
     # Calculate the TextRank scores
     tr_scores = defaultdict(float)
+    for token in doc:
+        for child in token.children:
+            tr_scores[token.text] += word_frequencies[child.text]
+
     for _ in range(10):  # Number of iterations for convergence
         for token in doc:
-            tr_scores[token.text] = (1 - 0.85) + 0.85 * sum(tr_scores[t.text] * word_frequencies[t.text] for t in token.children)
+            tr_scores[token.text] = (1 - 0.85) + 0.85 * sum(tr_scores[child.text] for child in token.children)
 
     # Sort the keywords by TextRank scores
     keywords = sorted(tr_scores, key=tr_scores.get, reverse=True)[:num_keywords]
 
-    return keywords
\ No newline at end of file
+    return keywords
+
+# Example usage
+if __name__ == "__main__":
+    sample_text = "Natural language processing enables computers to understand human language. It's a field of artificial intelligence."
+    print(extract_keywords_with_textrank(sample_text))
\ No newline at end of file
diff --git a/posts/urls.py b/posts/urls.py
index 5087b98..5766b78 100644
--- a/posts/urls.py
+++ b/posts/urls.py
@@ -1,10 +1,7 @@
 from django.urls import path
-from . import views
-
-app_name = 'posts'
+from .views import create_post, generated_post
 
 urlpatterns = [
-    path('post/new/', views.create_post, name='create_post'),
-    path('post/create/', views.create_post, name='post_create'),
-
+    path('create/', create_post, name='create_post'),
+     path('generated_post/', generated_post, name='generated_post'),
 ]
\ No newline at end of file
diff --git a/posts/views.py b/posts/views.py
index 0c789ed..0498517 100644
--- a/posts/views.py
+++ b/posts/views.py
@@ -1,19 +1,15 @@
 from django.shortcuts import render
 from .models import Post
-import nltk
+from .forms import PostCreationForm
+from .ner import extract_named_entities_with_spacy
+from .textrank import extract_keywords_with_textrank
+from .tfidf import apply_tfidf
 import string
-import numpy as np
 from nltk.corpus import stopwords
-from nltk.tokenize import word_tokenize
-from nltk.stem import PorterStemmer
 from nltk.stem import WordNetLemmatizer
-from sklearn.feature_extraction.text import TfidfVectorizer
-from sklearn.metrics.pairwise import cosine_similarity
-from sklearn.decomposition import TruncatedSVD
-import spacy
 from spacy.lang.en.stop_words import STOP_WORDS
 from spacy.lang.en import English
-from .ner import extract_named_entities_with_spacy
+import spacy  # Import spacy here
 
 # Load the spaCy language model
 nlp = spacy.load('en_core_web_sm')
@@ -38,48 +34,71 @@ def preprocess_input(text):
 
 def create_post(request):
     if request.method == 'POST':
-        # Retrieve user input from the form
-        subject = request.POST.get('subject')
-        important_things = request.POST.get('important_things')
-        libraries = request.POST.get('libraries')
-        frameworks = request.POST.get('frameworks')
-        tools = request.POST.get('tools')
-        best_practices = request.POST.get('best_practices')
-        benefits = request.POST.get('benefits')
-        examples = request.POST.get('examples')
-        implementation_instructions = request.POST.get('implementation_instructions')
-        installation_guidelines = request.POST.get('installation_guidelines')
-        settings = request.POST.get('settings')
-        things_to_avoid = request.POST.get('things_to_avoid')
-        top_keywords = request.POST.get('top_keywords')
-
-        # Preprocess the user input
-        preprocessed_subject = preprocess_input(subject)
-
-        # Apply spaCy for NER
-        named_entities = extract_named_entities_with_spacy(preprocessed_subject)
-
-        # Your remaining code for TF-IDF and keyword extraction can follow here
-
-        # Create a new post object
-        post = Post.objects.create(
-            subject=subject,
-            important_things=important_things,
-            libraries=libraries,
-            frameworks=frameworks,
-            tools=tools,
-            best_practices=best_practices,
-            benefits=benefits,
-            examples=examples,
-            implementation_instructions=implementation_instructions,
-            installation_guidelines=installation_guidelines,
-            settings=settings,
-            things_to_avoid=things_to_avoid,
-            named_entities=named_entities,
-            top_keywords=top_keywords,
-        )
-
-        # Render the generated post content to the user
-        return render(request, 'post.html', {'post': post})
-
-    return render(request, 'create_post.html')
+        form = PostCreationForm(request.POST)
+        if form.is_valid():
+            # Cleaned data from the form
+            cleaned_data = form.cleaned_data
+
+            # Preprocess the user input
+            preprocessed_subject = preprocess_input(cleaned_data['subject'])
+            preprocessed_important_things = preprocess_input(cleaned_data['important_things'])
+
+            # Apply spaCy for NER
+            named_entities_subject = extract_named_entities_with_spacy(preprocessed_subject)
+
+            # Create a list of preprocessed documents
+            preprocessed_documents = [
+                preprocessed_subject,
+                preprocessed_important_things,
+                preprocess_input(cleaned_data['libraries']),
+                preprocess_input(cleaned_data['frameworks']),
+                preprocess_input(cleaned_data['tools']),
+                preprocess_input(cleaned_data['best_practices']),
+                preprocess_input(cleaned_data['benefits']),
+                preprocess_input(cleaned_data['examples']),
+                preprocess_input(cleaned_data['implementation_instructions']),
+                preprocess_input(cleaned_data['installation_guidelines']),
+                preprocess_input(cleaned_data['settings']),
+                preprocess_input(cleaned_data['things_to_avoid']),
+                preprocess_input(cleaned_data['top_keywords']),
+            ]
+
+            # Apply TextRank for keyword extraction
+            textrank_keywords = extract_keywords_with_textrank(preprocessed_subject)
+
+            # Apply TF-IDF vectorization
+            tfidf_matrix, feature_names = apply_tfidf(preprocessed_documents)
+
+            # Create a new post object
+            post = Post.objects.create(
+                subject=preprocessed_subject,
+                important_things=preprocessed_important_things,
+                libraries=preprocess_input(cleaned_data['libraries']),
+                frameworks=preprocess_input(cleaned_data['frameworks']),
+                tools=preprocess_input(cleaned_data['tools']),
+                best_practices=preprocess_input(cleaned_data['best_practices']),
+                benefits=preprocess_input(cleaned_data['benefits']),
+                examples=preprocess_input(cleaned_data['examples']),
+                implementation_instructions=preprocess_input(cleaned_data['implementation_instructions']),
+                installation_guidelines=preprocess_input(cleaned_data['installation_guidelines']),
+                settings=preprocess_input(cleaned_data['settings']),
+                things_to_avoid=preprocess_input(cleaned_data['things_to_avoid']),
+                top_keywords=preprocess_input(cleaned_data['top_keywords']),
+                named_entities_subject=named_entities_subject,
+                textrank_keywords=textrank_keywords,
+            )
+
+            # Render the generated post content to the user
+            return render(request, 'post.html', {'post': post, 'tfidf_matrix': tfidf_matrix, 'feature_names': feature_names})
+
+    else:
+        form = PostCreationForm()
+
+    return render(request, 'create_post.html', {'form': form})
+
+def generated_post(request):
+    # Fetch the most recent post
+    latest_post = Post.objects.latest('created_at')
+
+    # Render the 'generated_post.html' template with the post data
+    return render(request, 'generated_post.html', {'post': latest_post})
\ No newline at end of file
diff --git a/project/__pycache__/settings.cpython-311.pyc b/project/__pycache__/settings.cpython-311.pyc
index 597c60c..6443a8d 100644
Binary files a/project/__pycache__/settings.cpython-311.pyc and b/project/__pycache__/settings.cpython-311.pyc differ
diff --git a/project/__pycache__/urls.cpython-311.pyc b/project/__pycache__/urls.cpython-311.pyc
index ceff860..b9a08ac 100644
Binary files a/project/__pycache__/urls.cpython-311.pyc and b/project/__pycache__/urls.cpython-311.pyc differ
diff --git a/project/settings.py b/project/settings.py
index 20e99d7..8a93d7e 100644
--- a/project/settings.py
+++ b/project/settings.py
@@ -9,12 +9,12 @@ https://docs.djangoproject.com/en/5.0/topics/settings/
 For the full list of settings and their values, see
 https://docs.djangoproject.com/en/5.0/ref/settings/
 """
-
+import os
 from pathlib import Path
 
 # Build paths inside the project like this: BASE_DIR / 'subdir'.
 BASE_DIR = Path(__file__).resolve().parent.parent
-
+BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
 
 # Quick-start development settings - unsuitable for production
 # See https://docs.djangoproject.com/en/5.0/howto/deployment/checklist/
diff --git a/project/urls.py b/project/urls.py
index 3db37b4..62cce47 100644
--- a/project/urls.py
+++ b/project/urls.py
@@ -15,8 +15,9 @@ Including another URLconf
     2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
 """
 from django.contrib import admin
-from django.urls import path
+from django.urls import path, include
 
 urlpatterns = [
     path('admin/', admin.site.urls),
-]
+    path('posts/', include('posts.urls')),
+]
\ No newline at end of file
diff --git a/requermentes.txt b/requermentes.txt
new file mode 100644
index 0000000..218e9b7
Binary files /dev/null and b/requermentes.txt differ


328015c - Abdullah Bakir, 9 days ago : test

commit 328015c0baa7a33cb24eadb3a8410ca228ab14d0
Author: Abdullah Bakir <abdullah.bakir.204@gmail.com>
Date:   Mon Dec 18 05:07:11 2023 +0100

    test

diff --git a/bot/__pycache__/__init__.cpython-311.pyc b/bot/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..cd336a8
Binary files /dev/null and b/bot/__pycache__/__init__.cpython-311.pyc differ
diff --git a/bot/__pycache__/apps.cpython-311.pyc b/bot/__pycache__/apps.cpython-311.pyc
new file mode 100644
index 0000000..4589aa7
Binary files /dev/null and b/bot/__pycache__/apps.cpython-311.pyc differ
diff --git a/db.sqlite3 b/db.sqlite3
new file mode 100644
index 0000000..08e8057
Binary files /dev/null and b/db.sqlite3 differ
diff --git a/manage.py b/manage.py
index 2c49f3a..b3f3357 100644
--- a/manage.py
+++ b/manage.py
@@ -2,7 +2,8 @@
 """Django's command-line utility for administrative tasks."""
 import os
 import sys
-
+import nltk
+from transformers import BertForSequenceClassification
 
 def main():
     """Run administrative tasks."""
@@ -15,6 +16,21 @@ def main():
             "available on your PYTHONPATH environment variable? Did you "
             "forget to activate a virtual environment?"
         ) from exc
+
+    # Import the necessary modules
+
+
+# Load the pre-trained BERT model
+    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)
+
+# Rest of your code
+# ...
+
+
+    # nltk.download('stopwords')
+    # nltk.download('punkt')
+    # nltk.download('wordnet')
+
     execute_from_command_line(sys.argv)
 
 
diff --git a/posts/__init__.py b/posts/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/posts/__pycache__/__init__.cpython-311.pyc b/posts/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..17e93b0
Binary files /dev/null and b/posts/__pycache__/__init__.cpython-311.pyc differ
diff --git a/posts/__pycache__/apps.cpython-311.pyc b/posts/__pycache__/apps.cpython-311.pyc
new file mode 100644
index 0000000..0dbd3ce
Binary files /dev/null and b/posts/__pycache__/apps.cpython-311.pyc differ
diff --git a/posts/admin.py b/posts/admin.py
new file mode 100644
index 0000000..c7a959e
--- /dev/null
+++ b/posts/admin.py
@@ -0,0 +1,3 @@
+from django.contrib import admin
+
+
diff --git a/posts/apps.py b/posts/apps.py
new file mode 100644
index 0000000..b18ed0d
--- /dev/null
+++ b/posts/apps.py
@@ -0,0 +1,6 @@
+from django.apps import AppConfig
+
+
+class PostsConfig(AppConfig):
+    default_auto_field = 'django.db.models.BigAutoField'
+    name = 'posts'
diff --git a/posts/bert_keyword_extraction.py b/posts/bert_keyword_extraction.py
new file mode 100644
index 0000000..099ff0d
--- /dev/null
+++ b/posts/bert_keyword_extraction.py
@@ -0,0 +1,39 @@
+from transformers import BertTokenizer, BertForTokenClassification
+import torch
+
+# Load the pre-trained BERT model and tokenizer
+model_name = 'bert-base-uncased'
+tokenizer = BertTokenizer.from_pretrained(model_name)
+model = BertForTokenClassification.from_pretrained(model_name)
+
+# Define the input text for keyword extraction
+input_text = "Your input text goes here."
+
+# Tokenize the input text
+tokens = tokenizer.tokenize(input_text)
+token_ids = tokenizer.convert_tokens_to_ids(tokens)
+
+# Add the special tokens [CLS] and [SEP]
+token_ids = [tokenizer.cls_token_id] + token_ids + [tokenizer.sep_token_id]
+
+# Convert the token IDs to tensors
+input_ids = torch.tensor([token_ids])
+
+# Run the BERT model for token classification
+outputs = model(input_ids)
+
+# Get the predicted token labels
+predicted_token_labels = torch.argmax(outputs.logits, dim=2).squeeze().tolist()
+
+# Extract the keywords from the input text
+keywords = []
+current_keyword = ""
+for token, label in zip(tokens, predicted_token_labels[1:-1]):
+    if label == 1:  # Check if the token is classified as a keyword
+        current_keyword += " " + token
+    elif current_keyword:
+        keywords.append(current_keyword.strip())
+        current_keyword = ""
+
+# Print the extracted keywords
+print(keywords)
diff --git a/posts/migrations/__init__.py b/posts/migrations/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/posts/models.py b/posts/models.py
new file mode 100644
index 0000000..9280d31
--- /dev/null
+++ b/posts/models.py
@@ -0,0 +1,24 @@
+from django.db import models
+
+
+class Post(models.Model):
+    subject = models.CharField(max_length=200)
+    important_things = models.TextField(null=True,blank=True)
+    libraries = models.TextField(null=True,blank=True)
+    frameworks = models.TextField(null=True,blank=True)
+    tools = models.TextField(null=True,blank=True)
+    best_practices = models.TextField(null=True,blank=True)
+    benefits = models.TextField(null=True,blank=True)
+    examples = models.TextField(null=True,blank=True)
+    implementation_instructions = models.TextField(null=True,blank=True)
+    installation_guidelines = models.TextField(null=True,blank=True)
+    settings = models.TextField(null=True,blank=True)
+    things_to_avoid = models.TextField(null=True,blank=True)
+    follow = models.TextField(null=True,blank=True)
+    created_at = models.DateTimeField(auto_now_add=True)
+    updated_at = models.DateTimeField(auto_now=True)
+    hashtags = models.TextField(null=True,blank=True)
+    top_keywords = models.TextField(null=True,blank=True)
+
+    def _str_(self):
+        return self.subject
\ No newline at end of file
diff --git a/posts/ner.py b/posts/ner.py
new file mode 100644
index 0000000..bfb308c
--- /dev/null
+++ b/posts/ner.py
@@ -0,0 +1,20 @@
+import spacy
+from spacy.lang.en import English
+
+def extract_named_entities_with_spacy(text):
+    nlp = spacy.load('en_core_web_sm')
+    tokenizer = English().Defaults.create_tokenizer(nlp)
+    
+    # Tokenize the text
+    tokens = tokenizer(text)
+    
+    # Create a spaCy document
+    doc = spacy.tokens.Doc(nlp.vocab, words=[token.text for token in tokens])
+    
+    # Apply named entity recognition
+    nlp.get_pipe("ner")(doc)
+    
+    # Extract named entities
+    named_entities = [ent.text for ent in doc.ents]
+    
+    return named_entities
\ No newline at end of file
diff --git a/posts/templates/posts/create_post.html b/posts/templates/posts/create_post.html
new file mode 100644
index 0000000..2057157
--- /dev/null
+++ b/posts/templates/posts/create_post.html
@@ -0,0 +1,52 @@
+<!DOCTYPE html>
+<html>
+<head>
+    <title>Create Post</title>
+</head>
+<body>
+    <h1>Create a New Post</h1>
+    <form method="POST" action="{% url 'create_post' %}">
+        {% csrf_token %}
+        <label for="subject">Subject:</label>
+        <input type="text" name="subject" id="subject" required><br><br>
+        
+        <label for="important_things">Important Things:</label>
+        <textarea name="important_things" id="important_things"></textarea><br><br>
+        
+        <label for="libraries">Libraries:</label>
+        <textarea name="libraries" id="libraries"></textarea><br><br>
+        
+        <label for="frameworks">Frameworks:</label>
+        <textarea name="frameworks" id="frameworks"></textarea><br><br>
+        
+        <label for="tools">Tools:</label>
+        <textarea name="tools" id="tools"></textarea><br><br>
+        
+        <label for="best_practices">Best Practices:</label>
+        <textarea name="best_practices" id="best_practices"></textarea><br><br>
+        
+        <label for="benefits">Benefits:</label>
+        <textarea name="benefits" id="benefits"></textarea><br><br>
+        
+        <label for="examples">Examples:</label>
+        <textarea name="examples" id="examples"></textarea><br><br>
+        
+        <label for="implementation_instructions">Implementation Instructions:</label>
+        <textarea name="implementation_instructions" id="implementation_instructions"></textarea><br><br>
+        
+        <label for="installation_guidelines">Installation Guidelines:</label>
+        <textarea name="installation_guidelines" id="installation_guidelines"></textarea><br><br>
+        
+        <label for="settings">Settings:</label>
+        <textarea name="settings" id="settings"></textarea><br><br>
+        
+        <label for="things_to_avoid">Things to Avoid:</label>
+        <textarea name="things_to_avoid" id="things_to_avoid"></textarea><br><br>
+        
+        <label for="top_keywords">Top Keywords:</label>
+        <textarea name="top_keywords" id="top_keywords"></textarea><br><br>
+        
+        <input type="submit" value="Create Post">
+    </form>
+</body>
+</html>
\ No newline at end of file
diff --git a/posts/templates/posts/post.html b/posts/templates/posts/post.html
new file mode 100644
index 0000000..36a1a9b
--- /dev/null
+++ b/posts/templates/posts/post.html
@@ -0,0 +1,46 @@
+<!DOCTYPE html>
+<html>
+<head>
+    <title>Generated Post</title>
+</head>
+<body>
+    <h1>Generated Post</h1>
+    <h2>{{ post.subject }}</h2>
+    
+    <h3>Important Things:</h3>
+    <p>{{ post.important_things }}</p>
+    
+    <h3>Libraries:</h3>
+    <p>{{ post.libraries }}</p>
+    
+    <h3>Frameworks:</h3>
+    <p>{{ post.frameworks }}</p>
+    
+    <h3>Tools:</h3>
+    <p>{{ post.tools }}</p>
+    
+    <h3>Best Practices:</h3>
+    <p>{{ post.best_practices }}</p>
+    
+    <h3>Benefits:</h3>
+    <p>{{ post.benefits }}</p>
+    
+    <h3>Examples:</h3>
+    <p>{{ post.examples }}</p>
+    
+    <h3>Implementation Instructions:</h3>
+    <p>{{ post.implementation_instructions }}</p>
+    
+    <h3>Installation Guidelines:</h3>
+    <p>{{ post.installation_guidelines }}</p>
+    
+    <h3>Settings:</h3>
+    <p>{{ post.settings }}</p>
+    
+    <h3>Things to Avoid:</h3>
+    <p>{{ post.things_to_avoid }}</p>
+    
+    <h3>Top Keywords:</h3>
+    <p>{{ post.top_keywords }}</p>
+</body>
+</html>
\ No newline at end of file
diff --git a/posts/tests.py b/posts/tests.py
new file mode 100644
index 0000000..7ce503c
--- /dev/null
+++ b/posts/tests.py
@@ -0,0 +1,3 @@
+from django.test import TestCase
+
+# Create your tests here.
diff --git a/posts/textrank.py b/posts/textrank.py
new file mode 100644
index 0000000..8c46bcb
--- /dev/null
+++ b/posts/textrank.py
@@ -0,0 +1,49 @@
+import spacy
+from spacy.lang.en.stop_words import STOP_WORDS
+from spacy.lang.en import English
+from collections import defaultdict
+import string
+
+# Load the spaCy language model
+nlp = spacy.load('en_core_web_sm')
+
+# Create a tokenizer
+tokenizer = English().Defaults.create_tokenizer(nlp)
+
+def preprocess_input(text):
+    # Tokenize the text
+    tokens = tokenizer(text)
+
+    # Remove stopwords and punctuation
+    tokens = [token.text.lower() for token in tokens if token.text.lower() not in STOP_WORDS and token.text not in string.punctuation]
+
+    # Join the tokens back into a string
+    preprocessed_text = ' '.join(tokens)
+    return preprocessed_text
+
+def extract_keywords_with_textrank(text, num_keywords=5):
+    # Preprocess the text
+    preprocessed_text = preprocess_input(text)
+
+    # Create a spaCy document
+    doc = nlp(preprocessed_text)
+
+    # Build the word frequency dictionary
+    word_frequencies = defaultdict(int)
+    for token in doc:
+        word_frequencies[token.text] += 1
+
+    # Normalize the word frequencies
+    max_frequency = max(word_frequencies.values())
+    word_frequencies = {word: freq / max_frequency for word, freq in word_frequencies.items()}
+
+    # Calculate the TextRank scores
+    tr_scores = defaultdict(float)
+    for _ in range(10):  # Number of iterations for convergence
+        for token in doc:
+            tr_scores[token.text] = (1 - 0.85) + 0.85 * sum(tr_scores[t.text] * word_frequencies[t.text] for t in token.children)
+
+    # Sort the keywords by TextRank scores
+    keywords = sorted(tr_scores, key=tr_scores.get, reverse=True)[:num_keywords]
+
+    return keywords
\ No newline at end of file
diff --git a/posts/tfidf.py b/posts/tfidf.py
new file mode 100644
index 0000000..6e15681
--- /dev/null
+++ b/posts/tfidf.py
@@ -0,0 +1,20 @@
+from sklearn.feature_extraction.text import TfidfVectorizer
+
+def apply_tfidf(corpus):
+    # Create a TF-IDF vectorizer
+    vectorizer = TfidfVectorizer(
+        max_features=500,  # Limit the number of features (terms)
+        stop_words='english',  # Remove common English stopwords
+        lowercase=True,  # Convert all text to lowercase
+        use_idf=True,  # Include IDF (Inverse Document Frequency) in the calculation
+        smooth_idf=True,  # Smooth IDF weights to prevent division by zero
+        sublinear_tf=True  # Apply sublinear TF scaling
+    )
+    
+    # Apply TF-IDF vectorization to the corpus
+    tfidf_matrix = vectorizer.fit_transform(corpus)
+    
+    # Get the feature names (terms)
+    feature_names = vectorizer.get_feature_names()
+    
+    return tfidf_matrix, feature_names
\ No newline at end of file
diff --git a/posts/urls.py b/posts/urls.py
new file mode 100644
index 0000000..5087b98
--- /dev/null
+++ b/posts/urls.py
@@ -0,0 +1,10 @@
+from django.urls import path
+from . import views
+
+app_name = 'posts'
+
+urlpatterns = [
+    path('post/new/', views.create_post, name='create_post'),
+    path('post/create/', views.create_post, name='post_create'),
+
+]
\ No newline at end of file
diff --git a/posts/utils.py b/posts/utils.py
new file mode 100644
index 0000000..4171874
--- /dev/null
+++ b/posts/utils.py
@@ -0,0 +1,25 @@
+import nltk
+from nltk.tokenize import word_tokenize
+from nltk.corpus import stopwords
+from nltk.stem import WordNetLemmatizer
+import string
+
+def preprocess_input(user_input):
+    # Tokenize the text into words
+    tokens = word_tokenize(user_input)
+    
+    # Remove punctuation
+    tokens = [token for token in tokens if token not in string.punctuation]
+    
+    # Convert to lowercase
+    tokens = [token.lower() for token in tokens]
+    
+    # Remove stop words
+    stop_words = set(stopwords.words('english'))
+    tokens = [token for token in tokens if token not in stop_words]
+    
+    # Perform lemmatization
+    lemmatizer = WordNetLemmatizer()
+    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]
+    
+    return lemmatized_tokens
\ No newline at end of file
diff --git a/posts/views.py b/posts/views.py
new file mode 100644
index 0000000..0c789ed
--- /dev/null
+++ b/posts/views.py
@@ -0,0 +1,85 @@
+from django.shortcuts import render
+from .models import Post
+import nltk
+import string
+import numpy as np
+from nltk.corpus import stopwords
+from nltk.tokenize import word_tokenize
+from nltk.stem import PorterStemmer
+from nltk.stem import WordNetLemmatizer
+from sklearn.feature_extraction.text import TfidfVectorizer
+from sklearn.metrics.pairwise import cosine_similarity
+from sklearn.decomposition import TruncatedSVD
+import spacy
+from spacy.lang.en.stop_words import STOP_WORDS
+from spacy.lang.en import English
+from .ner import extract_named_entities_with_spacy
+
+# Load the spaCy language model
+nlp = spacy.load('en_core_web_sm')
+
+# Create a tokenizer
+tokenizer = English().Defaults.create_tokenizer(nlp)
+
+def preprocess_input(text):
+    # Tokenize the text
+    tokens = tokenizer(text)
+
+    # Lemmatize the tokens
+    lemmatizer = WordNetLemmatizer()
+    tokens = [lemmatizer.lemmatize(token.text.lower()) for token in tokens]
+
+    # Remove stopwords and punctuation
+    tokens = [token for token in tokens if token not in STOP_WORDS and token not in string.punctuation]
+
+    # Join the tokens back into a string
+    preprocessed_text = ' '.join(tokens)
+    return preprocessed_text
+
+def create_post(request):
+    if request.method == 'POST':
+        # Retrieve user input from the form
+        subject = request.POST.get('subject')
+        important_things = request.POST.get('important_things')
+        libraries = request.POST.get('libraries')
+        frameworks = request.POST.get('frameworks')
+        tools = request.POST.get('tools')
+        best_practices = request.POST.get('best_practices')
+        benefits = request.POST.get('benefits')
+        examples = request.POST.get('examples')
+        implementation_instructions = request.POST.get('implementation_instructions')
+        installation_guidelines = request.POST.get('installation_guidelines')
+        settings = request.POST.get('settings')
+        things_to_avoid = request.POST.get('things_to_avoid')
+        top_keywords = request.POST.get('top_keywords')
+
+        # Preprocess the user input
+        preprocessed_subject = preprocess_input(subject)
+
+        # Apply spaCy for NER
+        named_entities = extract_named_entities_with_spacy(preprocessed_subject)
+
+        # Your remaining code for TF-IDF and keyword extraction can follow here
+
+        # Create a new post object
+        post = Post.objects.create(
+            subject=subject,
+            important_things=important_things,
+            libraries=libraries,
+            frameworks=frameworks,
+            tools=tools,
+            best_practices=best_practices,
+            benefits=benefits,
+            examples=examples,
+            implementation_instructions=implementation_instructions,
+            installation_guidelines=installation_guidelines,
+            settings=settings,
+            things_to_avoid=things_to_avoid,
+            named_entities=named_entities,
+            top_keywords=top_keywords,
+        )
+
+        # Render the generated post content to the user
+        return render(request, 'post.html', {'post': post})
+
+    return render(request, 'create_post.html')
diff --git a/project/__pycache__/settings.cpython-311.pyc b/project/__pycache__/settings.cpython-311.pyc
index 5c6f039..597c60c 100644
Binary files a/project/__pycache__/settings.cpython-311.pyc and b/project/__pycache__/settings.cpython-311.pyc differ
diff --git a/project/__pycache__/urls.cpython-311.pyc b/project/__pycache__/urls.cpython-311.pyc
new file mode 100644
index 0000000..ceff860
Binary files /dev/null and b/project/__pycache__/urls.cpython-311.pyc differ
diff --git a/project/__pycache__/wsgi.cpython-311.pyc b/project/__pycache__/wsgi.cpython-311.pyc
new file mode 100644
index 0000000..b89c667
Binary files /dev/null and b/project/__pycache__/wsgi.cpython-311.pyc differ
diff --git a/project/settings.py b/project/settings.py
index 6ed56d7..20e99d7 100644
--- a/project/settings.py
+++ b/project/settings.py
@@ -37,8 +37,21 @@ INSTALLED_APPS = [
     'django.contrib.sessions',
     'django.contrib.messages',
     'django.contrib.staticfiles',
+
+    # my apps
+    'bot',
+    'posts',
+
+    
+]
+
+LIBRARIES = [
+    
+
+    
 ]
 
+
 MIDDLEWARE = [
     'django.middleware.security.SecurityMiddleware',
     'django.contrib.sessions.middleware.SessionMiddleware',
@@ -76,7 +89,7 @@ WSGI_APPLICATION = 'project.wsgi.application'
 DATABASES = {
     'default': {
         'ENGINE': 'django.db.backends.sqlite3',
-        'NAME': BASE_DIR / 'db.sqlite3',
+        'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),
     }
 }
 
diff --git a/todo.md b/todo.md
new file mode 100644
index 0000000..2684fd7
--- /dev/null
+++ b/todo.md
@@ -0,0 +1,58 @@
+Install the necessary libraries, such as Django Channels, TensorFlow, and Django Rest Framework.
+
+Set up the database.
+
+        - Create a model for the AI chatbot. This model should contain the information necessary for the AI chatbot to generate LinkedIn or medium posts, such as post subject, important things, libraries, frameworks, tools, best practices, benefits, examples, settings, and things to avoid.
+
+        Data Collection:
+
+        Collect a diverse dataset of blog posts, articles, and resources related to programming, software development, data science, machine learning, AI, and their related technologies.
+        Data can be collected from LinkedIn, Medium, personal blogs, or academic websites.
+        Data Preprocessing:
+
+        Clean the data by removing any irrelevant information, special characters, numbers, and punctuation marks.
+        Tokenize the data into words, phrases, or sentences.
+        Remove stop words like 'and', 'or', 'is', 'are', etc.
+        Perform lemmatization or stemming to reduce words to their base form.
+        Model Building:
+
+        Train the model on the cleaned data.
+        Utilize techniques like sequence-to-sequence (seq2seq) model, attention mechanism, and transformer architecture to enable the AI chatbot to understand the context of the user's query and generate a coherent response.
+        The model can be trained using popular deep learning frameworks like TensorFlow or PyTorch.
+        Model Training and Testing:
+
+        Divide the data into training, validation, and testing sets.
+        Train the model using the training data.
+        Evaluate the model's performance using the validation and testing sets.
+        Adjust the model's hyperparameters to optimize its performance.
+        Deployment:
+
+        Once the model is trained and optimized, it can be deployed to a cloud platform or server for real-time interaction with users.
+        Users can interact with the AI chatbot by sending queries related to programming, software development, data science, machine learning, AI, and their related technologies.
+        The AI chatbot will generate a LinkedIn or medium post by using the trained model and providing users with the requested information.
+
+
+Create a form for the user to input their post subject and desired level of detail.
+
+Implement a Natural Language Processing (NLP) model, such as BERT, to process the user's input and generate relevant information.
+
+Set up a view for the user to submit their post subject and desired level of detail. This view should take the user's input and pass it to the NLP model.
+
+Create a template for the view that allows the user to submit their post subject and desired level of detail.
+
+Implement a method to search the internet for the best answers to the user's questions. This can be done using a search engine API, such as Google's Custom Search JSON API.
+
+Train the NLP model using a dataset of relevant posts, including important things, libraries, frameworks, tools, best practices, benefits, examples, settings, and things to avoid.
+
+Create a method to generate a LinkedIn or medium post based on the user's input and the information generated by the NLP model.
+
+Set up a view for the user to edit their post or regenerate it. This view should take the user's input and pass it to the NLP model, which should then generate a new post based on the user's updated input.
+
+Implement a REST API for the chatbot, allowing users to create posts, edit them, and regenerate them.
+
+Set up the frontend of the chatbot using a framework like React.js.
+
+Deploy the chatbot using a cloud provider, such as AWS or Google Cloud Platform.
+
+
+


3181f00 - Abdullah Bakir, 10 days ago : starting project

commit 3181f0043c0dda69e7ec39d5e394c10ff4a4bbc5
Author: Abdullah Bakir <abdullah.bakir.204@gmail.com> on Sun Dec 17 03:53:41 2023 +0100

    starting project:
diff --git a/bot/__init__.py b/bot/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/bot/admin.py b/bot/admin.py
new file mode 100644
index 0000000..8c38f3f
--- /dev/null
+++ b/bot/admin.py
@@ -0,0 +1,3 @@
+from django.contrib import admin
+
+# Register your models here.
diff --git a/bot/apps.py b/bot/apps.py
new file mode 100644
index 0000000..1cd7ff2
--- /dev/null
+++ b/bot/apps.py
@@ -0,0 +1,6 @@
+from django.apps import AppConfig
+
+
+class BotConfig(AppConfig):
+    default_auto_field = 'django.db.models.BigAutoField'
+    name = 'bot'
diff --git a/bot/migrations/__init__.py b/bot/migrations/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/bot/models.py b/bot/models.py
new file mode 100644
index 0000000..71a8362
--- /dev/null
+++ b/bot/models.py
@@ -0,0 +1,3 @@
+from django.db import models
+
+# Create your models here.
diff --git a/bot/tests.py b/bot/tests.py
new file mode 100644
index 0000000..7ce503c
--- /dev/null
+++ b/bot/tests.py
@@ -0,0 +1,3 @@
+from django.test import TestCase
+
+# Create your tests here.
diff --git a/bot/views.py b/bot/views.py
new file mode 100644
index 0000000..91ea44a
--- /dev/null
+++ b/bot/views.py
@@ -0,0 +1,3 @@
+from django.shortcuts import render
+
+# Create your views here.
diff --git a/manage.py b/manage.py
new file mode 100644
index 0000000..2c49f3a
--- /dev/null
+++ b/manage.py
@@ -0,0 +1,22 @@
+#!/usr/bin/env python
+"""Django's command-line utility for administrative tasks."""
+import os
+import sys
+
+
+def main():
+    """Run administrative tasks."""
+    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'project.settings')
+    try:
+        from django.core.management import execute_from_command_line
+    except ImportError as exc:
+        raise ImportError(
+            "Couldn't import Django. Are you sure it's installed and "
+            "available on your PYTHONPATH environment variable? Did you "
+            "forget to activate a virtual environment?"
+        ) from exc
+    execute_from_command_line(sys.argv)
+
+
+if __name__ == '__main__':
+    main()
diff --git a/project/__init__.py b/project/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/project/__pycache__/__init__.cpython-311.pyc b/project/__pycache__/__init__.cpython-311.pyc
new file mode 100644
index 0000000..5637ceb
Binary files /dev/null and b/project/__pycache__/__init__.cpython-311.pyc differ
diff --git a/project/__pycache__/settings.cpython-311.pyc b/project/__pycache__/settings.cpython-311.pyc
new file mode 100644
index 0000000..5c6f039
Binary files /dev/null and b/project/__pycache__/settings.cpython-311.pyc differ
diff --git a/project/asgi.py b/project/asgi.py
new file mode 100644
index 0000000..ff802aa
--- /dev/null
+++ b/project/asgi.py
@@ -0,0 +1,16 @@
+"""
+ASGI config for project project.
+
+It exposes the ASGI callable as a module-level variable named ``application``.
+
+For more information on this file, see
+https://docs.djangoproject.com/en/5.0/howto/deployment/asgi/
+"""
+
+import os
+
+from django.core.asgi import get_asgi_application
+
+os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'project.settings')
+
+application = get_asgi_application()
diff --git a/project/settings.py b/project/settings.py
new file mode 100644
index 0000000..6ed56d7
--- /dev/null
+++ b/project/settings.py
@@ -0,0 +1,123 @@
+"""
+Django settings for project project.
+
+Generated by 'django-admin startproject' using Django 5.0.
+
+For more information on this file, see
+https://docs.djangoproject.com/en/5.0/topics/settings/
+
+For the full list of settings and their values, see
+https://docs.djangoproject.com/en/5.0/ref/settings/
+"""
+
+from pathlib import Path
+
+# Build paths inside the project like this: BASE_DIR / 'subdir'.
+BASE_DIR = Path(__file__).resolve().parent.parent
+
+
+# Quick-start development settings - unsuitable for production
+# See https://docs.djangoproject.com/en/5.0/howto/deployment/checklist/
+
+# SECURITY WARNING: keep the secret key used in production secret!
+SECRET_KEY = 'django-insecure-3h_lg@8g$mdq0ilftlno6v=4+gx@ht-m^+hc+r1s!+mx*juexl'
+
+# SECURITY WARNING: don't run with debug turned on in production!
+DEBUG = True
+
+ALLOWED_HOSTS = []
+
+
+# Application definition
+
+INSTALLED_APPS = [
+    'django.contrib.admin',
+    'django.contrib.auth',
+    'django.contrib.contenttypes',
+    'django.contrib.sessions',
+    'django.contrib.messages',
+    'django.contrib.staticfiles',
+]
+
+MIDDLEWARE = [
+    'django.middleware.security.SecurityMiddleware',
+    'django.contrib.sessions.middleware.SessionMiddleware',
+    'django.middleware.common.CommonMiddleware',
+    'django.middleware.csrf.CsrfViewMiddleware',
+    'django.contrib.auth.middleware.AuthenticationMiddleware',
+    'django.contrib.messages.middleware.MessageMiddleware',
+    'django.middleware.clickjacking.XFrameOptionsMiddleware',
+]
+
+ROOT_URLCONF = 'project.urls'
+
+TEMPLATES = [
+    {
+        'BACKEND': 'django.template.backends.django.DjangoTemplates',
+        'DIRS': [],
+        'APP_DIRS': True,
+        'OPTIONS': {
+            'context_processors': [
+                'django.template.context_processors.debug',
+                'django.template.context_processors.request',
+                'django.contrib.auth.context_processors.auth',
+                'django.contrib.messages.context_processors.messages',
+            ],
+        },
+    },
+]
+
+WSGI_APPLICATION = 'project.wsgi.application'
+
+
+# Database
+# https://docs.djangoproject.com/en/5.0/ref/settings/#databases
+
+DATABASES = {
+    'default': {
+        'ENGINE': 'django.db.backends.sqlite3',
+        'NAME': BASE_DIR / 'db.sqlite3',
+    }
+}
+
+
+# Password validation
+# https://docs.djangoproject.com/en/5.0/ref/settings/#auth-password-validators
+
+AUTH_PASSWORD_VALIDATORS = [
+    {
+        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
+    },
+    {
+        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
+    },
+    {
+        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
+    },
+    {
+        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
+    },
+]
+
+
+# Internationalization
+# https://docs.djangoproject.com/en/5.0/topics/i18n/
+
+LANGUAGE_CODE = 'en-us'
+
+TIME_ZONE = 'UTC'
+
+USE_I18N = True
+
+USE_TZ = True
+
+
+# Static files (CSS, JavaScript, Images)
+# https://docs.djangoproject.com/en/5.0/howto/static-files/
+
+STATIC_URL = 'static/'
+
+# Default primary key field type
+# https://docs.djangoproject.com/en/5.0/ref/settings/#default-auto-field
+
+DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'
diff --git a/project/urls.py b/project/urls.py
new file mode 100644
index 0000000..3db37b4
--- /dev/null
+++ b/project/urls.py
@@ -0,0 +1,22 @@
+"""
+URL configuration for project project.
+
+The `urlpatterns` list routes URLs to views. For more information please see:
+    https://docs.djangoproject.com/en/5.0/topics/http/urls/
+Examples:
+Function views
+    1. Add an import:  from my_app import views
+    2. Add a URL to urlpatterns:  path('', views.home, name='home')
+Class-based views
+    1. Add an import:  from other_app.views import Home
+    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
+Including another URLconf
+    1. Import the include() function: from django.urls import include, path
+    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
+"""
+from django.contrib import admin
+from django.urls import path
+
+urlpatterns = [
+    path('admin/', admin.site.urls),
+]
diff --git a/project/wsgi.py b/project/wsgi.py
new file mode 100644
index 0000000..684174a
--- /dev/null
+++ b/project/wsgi.py
@@ -0,0 +1,16 @@
+"""
+WSGI config for project project.
+
+It exposes the WSGI callable as a module-level variable named ``application``.
+
+For more information on this file, see
+https://docs.djangoproject.com/en/5.0/howto/deployment/wsgi/
+"""
+
+import os
+
+from django.core.wsgi import get_wsgi_application
+
+os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'project.settings')
+
+application = get_wsgi_application()

